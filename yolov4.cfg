[net]
batch=64
subdivisions=32
# Training
#width=512
#height=512
width=416
height=416
channels=3
momentum=0.949
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.0013
burn_in=1000
max_batches = 805000
policy=steps
steps=640000,720000
scales=.1,.1

#cutmix=1
mosaic=1


### Clamp Control
### input
### quantize

### prune
train_prune=1
train_prune_batch=100
train_prune_batch_step=40
train_sparsity=80
train_sigma=0.3
### quantize

### fuse

#0
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=mish

train_prune=0
train_parsity=15
train_sigma=0.2

# Downsample
#1
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=mish

train_prune=0
train_parsity=15
train_sigma=0.2

#2
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

train_prune=0
train_parsity=15
train_sigma=0.2

#3
[route]
layers = -2

#4
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

train_prune=0
train_parsity=15
train_sigma=0.2

#5
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=mish

train_prune=0
train_parsity=15
train_sigma=0.2

#6
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

[shortcut]
from=-3
activation=linear

#8
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

[route]
layers = -1,-7

#10
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

# Downsample
#11
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#12
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

[route]
layers = -2

#14
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#15
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#16
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

[shortcut]
from=-3
activation=linear

#18
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#19
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

[shortcut]
from=-3
activation=linear

#21
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

[route]
layers = -1,-10

#23
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

# Downsample
#24
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

#25
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

[route]
layers = -2

#27
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#28
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#29
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#31
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#32
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#34
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#35
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#37
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#38
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#40
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#41
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#43
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#44
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#46
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#47
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#49
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#50
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#52
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

[route]
layers = -1,-28

#54
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

# Downsample
#55
[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=mish

train_prune=1
train_parsity=98
train_sigma=0.75

#56
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[route]
layers = -2

#58
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

#59
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#60
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#62
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#63
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#65
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#66
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#68
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#69
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#71
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#72
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#74
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#75
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#77
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#78
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#80
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

#81
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[shortcut]
from=-3
activation=linear

#83
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=85
train_sigma=0.45

[route]
layers = -1,-28

#85
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

# Downsample
#86
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=mish

train_prune=1
train_parsity=98
train_sigma=0.75

#87
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[route]
layers = -2

#89
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

#90
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

#91
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=98
train_sigma=0.75

[shortcut]
from=-3
activation=linear

#93
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

#94
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=98
train_sigma=0.75

[shortcut]
from=-3
activation=linear

#96
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

#97
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=98
train_sigma=0.75

[shortcut]
from=-3
activation=linear

#99
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

#100
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=98
train_sigma=0.75

[shortcut]
from=-3
activation=linear

#102
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=95
train_sigma=0.55

[route]
layers = -1,-16

#104
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=1
activation=mish

train_prune=1
train_parsity=98
train_sigma=0.75
##########################

#105
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#106
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#107
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

### SPP ###
[maxpool]
stride=1
size=5

[route]
layers=-2

[maxpool]
stride=1
size=9

[route]
layers=-4

[maxpool]
stride=1
size=13

[route]
layers=-1,-3,-5,-6
### End SPP ###

#114
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#115
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#116
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#117
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

[upsample]
stride=2

[route]
layers = 85

#120
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

[route]
layers = -1, -3

#122
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=85
train_sigma=0.45

#123
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#124
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=85
train_sigma=0.45

#125
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#126
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#127
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=85
train_sigma=0.45

[upsample]
stride=2

[route]
layers = 54

#130
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=85
train_sigma=0.45

[route]
layers = -1, -3

#132
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=85
train_sigma=0.45

#133
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#134
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=85
train_sigma=0.45

#135
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#136
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=85
train_sigma=0.45

##########################
#137
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

train_prune=1
train_parsity=85
train_sigma=0.45

#138
[convolutional]
size=1
stride=1
pad=1
filters=75
activation=linear

train_prune=1
train_parsity=85
train_sigma=0.45

[yolo]
mask = 0,1,2
anchors = 33,47, 50,107, 127,96, 78,200, 178,179, 128,293, 331,195, 226,326, 365,359
classes=20
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.2
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
max_delta=5


[route]
layers = -4

#141
[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=256
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55


[route]
layers = -1, -16

#143
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#144
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#145
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#146
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#147
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#148
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#149
[convolutional]
size=1
stride=1
pad=1
filters=75
activation=linear

train_prune=1
train_parsity=85
train_sigma=0.45


[yolo]
mask = 3,4,5
anchors = 33,47, 50,107, 127,96, 78,200, 178,179, 128,293, 331,195, 226,326, 365,359
classes=20
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.1
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
max_delta=5


[route]
layers = -4

#152
[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=512
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

[route]
layers = -1, -37

#154
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#155
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#156
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#157
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#158
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

train_prune=1
train_parsity=95
train_sigma=0.55

#159
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

train_prune=1
train_parsity=98
train_sigma=0.75

#160
[convolutional]
size=1
stride=1
pad=1
filters=75
activation=linear

train_prune=1
train_parsity=85
train_sigma=0.45

[yolo]
mask = 6,7,8
anchors = 33,47, 50,107, 127,96, 78,200, 178,179, 128,293, 331,195, 226,326, 365,359
classes=20
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
max_delta=5

